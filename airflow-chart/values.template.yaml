executor: CeleryExecutor

env:
  - name: MSSQL_PASSWORD
    value: $MSSQL_SECRET
  - name: AIRFLOW__PROVIDERS_ODBC__ALLOW_DRIVER_IN_EXTRA
    value: "true"
    
webserverSecretKeySecretName: my-airflow-secret

images:
  airflow:
    repository: $AIRFLOW_REPO
    tag: latest
    pullPolicy: Always

nodeSelector:
  kubernetes.io/hostname: $NODE3_NAME

workers:
  persistence:
    storageClassName: $DEFAULT_STORAGE_CLASS
  livenessProbe:
    timeoutSeconds: 60
    periodSeconds: 60
    failureThreshold: 3
    initialDelaySeconds: 30
  replicas: 2
  keda:
    enabled: true
    minReplicaCount: 2
    maxReplicaCount: 3
    pollingInterval: 30
    cooldownPeriod: 180
  resources:
    requests:
      cpu: "300m"
      memory: "768Mi"
    limits:
      cpu: "750m"
      memory: "2Gi"

config:
  celery:
    worker_concurrency: 2

triggerer:
  persistence:
    storageClassName: $DEFAULT_STORAGE_CLASS
  replicas: 1
  resources:
    requests:
      cpu: "200m"
      memory: "768Mi"
    limits:
      cpu: "500m"
      memory: "1Gi"
  livenessProbe:
    timeoutSeconds: 60
    periodSeconds: 60
    failureThreshold: 3
    initialDelaySeconds: 20

redis:
  persistence:
    storageClassName: $DEFAULT_STORAGE_CLASS

dags:
  persistence:
    storageClassName: $DEFAULT_STORAGE_CLASS
  gitSync:
    enabled: true
    repo: $GIT_REPO
    branch: master
    subPath: "dags"
    credentialsSecret: git-credentials
    ref: HEAD
    period: 15s

logs:
  persistence:
    storageClassName: $DEFAULT_STORAGE_CLASS

postgresql:
  primary:
    persistence:
      storageClass: $DEFAULT_STORAGE_CLASS

webserver:
  enabled: false

apiServer:
  waitForMigrations:
    enabled: false

  startupProbe:
    initialDelaySeconds: 20
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 30
    scheme: HTTP

  readinessProbe:
    initialDelaySeconds: 15
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 10
    scheme: HTTP

  livenessProbe:
    initialDelaySeconds: 15
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 10
    scheme: HTTP

  resources:
    requests:
      cpu: "200m"
      memory: "768Mi"
    limits:
      cpu: "700m"
      memory: "1560Mi"
  service:
    type: NodePort
    ports:
      - name: api-server
        port: 8080
        targetPort: api-server
        nodePort: $AIRFLOW_NODEPORT
  env:
    - name: AIRFLOW__API__BASE_URL
      value: "http://airflow.local"
    - name: AIRFLOW__API__WORKERS
      value: "1"

scheduler:
  livenessProbe:
    timeoutSeconds: 90
    periodSeconds: 60
    failureThreshold: 5
  replicas: 1
  resources:
    requests:
      cpu: "400m"
      memory: "768Mi"
    limits:
      cpu: "600m"
      memory: "1Gi"

dagProcessor:
  replicas: 1
  resources:
    requests:
      cpu: "500m"
      memory: "1280Mi"
    limits:
      cpu: "1"
      memory: "2Gi"
  livenessProbe:
    timeoutSeconds: 60
    periodSeconds: 60
    failureThreshold: 5
    initialDelaySeconds: 30